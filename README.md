# Compressor
Стиснення тексту за допомогою генеративної моделі
Автори: Баклан Аліса, Кіндякова Діана, Віткіна Анна Група МІ-4

Посилання:
Генеретавна межа Tereveni: https://huggingface.co/Tereveni-AI/gpt2-124M-uk-fiction
Блокнот GC: https://colab.research.google.com/drive/18UlMxPBZkGR8DUmiOAJvTzv_wFwecTtp#scrollTo=Rc5PwS2SmpHC

Програма складається з виконуваного файлу написаного мовою Python. Реалізація підтримує стиснення та розтиснення україномовного тексту на основі генеративної моделі «Tereveni-AI»[1] та є легко адаптивною для використання з іншими генеративними моделями.

Особливості вибраної моделі
Вибрана для стиснення GPT2 модель натренована на корпусі з 4040 книжок української художньої літератури загальним обсягом 2.77 GB. Можливе і бажане покращення моделі на корпусі БрУК та/або Uber Text 2.0.

Параметри конфігурації 
SHOW_TOKENS - Чи виводить токени, на які розбивається вхідний текст.
SHOW_PREDICTION - Чи виводити варіанти передбачень наступного слова.
PREDICT_WINDOW - Максимальна довжина тексту на основі, якого відбувається генерація наступного слова.
NUM_WORDS - Скільки варіантів передбачень наступного слова розглядаємо.


Програма підтримує загалом два типи команд (без врахування команд завершення роботи та виведення списку доступних команд): compress (стиснення) та decompress (розтиснення), які запитують назву необхідного файлу в користувача. 
